#!/usr/bin/env python3
"""
å¹¶è¡ŒSubagentæ‰§è¡Œå¼•æ“

åŠŸèƒ½ï¼š
1. è§£æv2 JSONè®¡åˆ’ï¼ˆåŒ…å«subtaskså’Œaggregationé…ç½®ï¼‰
2. ä¸ºæ¯ä¸ªtaskçš„subtasksç”Ÿæˆå¹¶è¡ŒTaskè°ƒç”¨
3. æ”¶é›†å’ŒèšåˆJSONç»“æœ
4. è·Ÿè¸ªæ€§èƒ½æŒ‡æ ‡ï¼ŒéªŒè¯ä¼˜åŒ–æ•ˆæœ

ä½¿ç”¨æ–¹æ³•ï¼š
python parallel_executor.py nvidia-dcf-valuation-plan-v2-parallel.json
"""

import json
import sys
import time
from pathlib import Path
from typing import Dict, List, Any, Tuple
from datetime import datetime


class ParallelExecutor:
    """å¹¶è¡ŒSubagentæ‰§è¡Œå¼•æ“"""

    def __init__(self, plan_path: str):
        self.plan_path = Path(plan_path)
        self.plan = self._load_plan()
        self.execution_log = []
        self.start_time = None

    def _load_plan(self) -> Dict[str, Any]:
        """åŠ è½½å¹¶éªŒè¯JSONè®¡åˆ’"""
        with open(self.plan_path, 'r', encoding='utf-8') as f:
            plan = json.load(f)

        # éªŒè¯v2æ ¼å¼
        if not plan.get('version', '').startswith('2.'):
            raise ValueError(f"éœ€è¦v2æ ¼å¼è®¡åˆ’ï¼Œå½“å‰ç‰ˆæœ¬: {plan.get('version')}")

        return plan

    def _build_wave_structure(self) -> List[List[int]]:
        """æ ¹æ®ä¾èµ–å…³ç³»æ„å»ºæ³¢æ¬¡æ‰§è¡Œç»“æ„"""
        tasks = {t['id']: t for t in self.plan['tasks']}
        waves = []
        completed = set()

        while len(completed) < len(tasks):
            # æ‰¾å‡ºæ‰€æœ‰ä¾èµ–å·²æ»¡è¶³çš„ä»»åŠ¡
            ready = []
            for task_id, task in tasks.items():
                if task_id not in completed:
                    deps = task.get('dependencies', [])
                    if all(d in completed for d in deps):
                        ready.append(task_id)

            if not ready:
                raise ValueError("æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–")

            waves.append(ready)
            completed.update(ready)

        return waves

    def _generate_subtask_prompt(self, task: Dict, subtask: Dict) -> str:
        """ä¸ºsubtaskç”ŸæˆAgentæç¤ºè¯"""
        topic = self.plan['topic']

        prompt = f"""ä½ æ˜¯é‡‘èç ”ç©¶ä¸“å®¶ï¼Œæ­£åœ¨æ‰§è¡Œä»¥ä¸‹ç ”ç©¶ä»»åŠ¡çš„ä¸€ä¸ªå­ä»»åŠ¡ï¼š

# ç ”ç©¶ä¸»é¢˜
{topic}

# ä¸»ä»»åŠ¡
{task['description']}

# ä½ çš„å­ä»»åŠ¡
{subtask['description']}

# æ•°æ®æŸ¥è¯¢è¦æ±‚
"""

        if 'data_queries' in subtask:
            prompt += "è¯·ä½¿ç”¨MCPå·¥å…·æŸ¥è¯¢ä»¥ä¸‹æ•°æ®ï¼š\n"
            for i, query in enumerate(subtask['data_queries'], 1):
                prompt += f"{i}. {query}\n"
        elif 'task' in subtask:
            prompt += f"{subtask['task']}\n"

        # è¾“å‡ºæ ¼å¼è¦æ±‚
        output_format = subtask.get('output_format', 'json')
        if output_format == 'json':
            prompt += """
# è¾“å‡ºæ ¼å¼
è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼ŒåŒ…å«ï¼š
```json
{
  "subtask_id": "å­ä»»åŠ¡ID",
  "data": {
    // æŸ¥è¯¢åˆ°çš„æ•°æ®ï¼Œç»“æ„åŒ–ç»„ç»‡
  },
  "summary": "æ•°æ®æ‘˜è¦ï¼ˆ1-2å¥è¯ï¼‰"
}
```
"""
        else:
            prompt += f"\n# è¾“å‡ºæ ¼å¼\n{output_format}\n"

        return prompt

    def _generate_aggregation_prompt(self, task: Dict, subtask_results: List[Dict]) -> str:
        """ä¸ºaggregationç”Ÿæˆæç¤ºè¯"""
        topic = self.plan['topic']
        agg_config = task['aggregation']

        prompt = f"""ä½ æ˜¯é‡‘èç ”ç©¶ä¸“å®¶ï¼Œæ­£åœ¨æ•´åˆå­ä»»åŠ¡çš„åˆ†æç»“æœã€‚

# ç ”ç©¶ä¸»é¢˜
{topic}

# ä¸»ä»»åŠ¡
{task['description']}

# å­ä»»åŠ¡ç»“æœ
ä»¥ä¸‹æ˜¯{len(subtask_results)}ä¸ªå¹¶è¡Œå­ä»»åŠ¡çš„ç»“æœï¼š

"""

        for i, result in enumerate(subtask_results, 1):
            prompt += f"## å­ä»»åŠ¡{i}: {result.get('subtask_id', f'subtask-{i}')}\n"
            prompt += f"```json\n{json.dumps(result.get('data', {}), indent=2, ensure_ascii=False)}\n```\n\n"

        prompt += f"""
# ä½ çš„ä»»åŠ¡
{agg_config['description']}

# è¾“å‡ºè¦æ±‚
- å­—æ•°ï¼šçº¦{agg_config.get('estimated_time', '90ç§’')}å¯¹åº”çš„å†…å®¹é‡
- ç»“æ„ï¼šæ¸…æ™°çš„ç« èŠ‚å’Œè¦ç‚¹
- æ•°æ®ï¼šå¼•ç”¨å…·ä½“æ•°å­—å’Œè¶‹åŠ¿
- åˆ†æï¼šæä¾›æ´å¯Ÿå’Œç»“è®º
"""

        return prompt

    def execute_task_with_parallel_subagents(self, task: Dict) -> Tuple[str, float]:
        """æ‰§è¡Œå•ä¸ªtaskï¼Œä½¿ç”¨å¹¶è¡Œsubagentæ¨¡å¼"""
        task_id = task['id']
        task_desc = task['description']

        print(f"\n{'='*60}")
        print(f"Task {task_id}: {task_desc}")
        print(f"{'='*60}")

        task_start = time.time()

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å¹¶è¡Œsubagentç­–ç•¥
        if task.get('execution_strategy') != 'parallel_subagents':
            print(f"âš ï¸  Task {task_id} ä¸ä½¿ç”¨å¹¶è¡Œsubagentç­–ç•¥ï¼Œè·³è¿‡")
            return None, 0

        subtasks = task.get('subtasks', [])
        if not subtasks:
            print(f"âš ï¸  Task {task_id} æ²¡æœ‰å®šä¹‰subtasksï¼Œè·³è¿‡")
            return None, 0

        print(f"\nğŸ“‹ å°†å¹¶è¡Œæ‰§è¡Œ {len(subtasks)} ä¸ªå­ä»»åŠ¡:")
        for st in subtasks:
            print(f"  - {st['id']}: {st['description']}")

        # ç”Ÿæˆå¹¶è¡ŒTaskè°ƒç”¨æŒ‡ä»¤
        print(f"\nğŸš€ ç”Ÿæˆå¹¶è¡ŒTaskè°ƒç”¨é…ç½®...")

        parallel_calls = []
        for subtask in subtasks:
            prompt = self._generate_subtask_prompt(task, subtask)
            model = subtask.get('model', 'haiku')

            call_config = {
                'subtask_id': subtask['id'],
                'description': subtask['description'],
                'model': model,
                'prompt': prompt,
                'estimated_time': subtask.get('estimated_time', 'æœªçŸ¥')
            }
            parallel_calls.append(call_config)

        # æ˜¾ç¤ºè°ƒç”¨é…ç½®
        print(f"\nğŸ“ å¹¶è¡Œè°ƒç”¨é…ç½®:")
        for i, call in enumerate(parallel_calls, 1):
            print(f"  {i}. Subtask {call['subtask_id']}: {call['description']}")
            print(f"     Model: {call['model']}, Est: {call['estimated_time']}")

        # âš ï¸ æ³¨æ„ï¼šåœ¨å®é™…Claude Codeç¯å¢ƒä¸­ï¼Œè¿™é‡Œåº”è¯¥ä½¿ç”¨Task toolå¹¶è¡Œè°ƒç”¨
        # ç¤ºä¾‹XMLç»“æ„ï¼ˆåœ¨Claude Codeä¸­å®é™…æ‰§è¡Œï¼‰ï¼š
        # <function_calls>
        #   <invoke name="Task">
        #     <parameter name="subagent_type">general-purpose</parameter>
        #     <parameter name="description">å­ä»»åŠ¡1æè¿°</parameter>
        #     <parameter name="model">haiku</parameter>
        #     <parameter name="prompt">...</parameter>
        #   </invoke>
        #   <invoke name="Task">
        #     <parameter name="subagent_type">general-purpose</parameter>
        #     <parameter name="description">å­ä»»åŠ¡2æè¿°</parameter>
        #     <parameter name="model">haiku</parameter>
        #     <parameter name="prompt">...</parameter>
        #   </invoke>
        #   ...
        # </function_calls>

        print(f"\nâ³ æ¨¡æ‹Ÿå¹¶è¡Œæ‰§è¡Œï¼ˆå®é™…ç¯å¢ƒä¸­å°†ä½¿ç”¨Task toolï¼‰...")

        # æ¨¡æ‹Ÿç»“æœï¼ˆå®é™…åº”ä»Task toolè·å–ï¼‰
        subtask_results = []
        for call in parallel_calls:
            result = {
                'subtask_id': call['subtask_id'],
                'data': {'æ¨¡æ‹Ÿæ•°æ®': f"è¿™æ˜¯{call['subtask_id']}çš„æ¨¡æ‹Ÿç»“æœ"},
                'summary': f"{call['description']}å®Œæˆ"
            }
            subtask_results.append(result)

        subtask_duration = time.time() - task_start
        print(f"âœ… {len(subtask_results)}ä¸ªå­ä»»åŠ¡å®Œæˆï¼Œè€—æ—¶: {subtask_duration:.1f}ç§’")

        # Aggregationé˜¶æ®µ
        agg_start = time.time()
        agg_config = task.get('aggregation', {})

        if agg_config:
            print(f"\nğŸ”„ èšåˆé˜¶æ®µ: {agg_config['description']}")
            agg_prompt = self._generate_aggregation_prompt(task, subtask_results)
            agg_model = agg_config.get('model', 'sonnet')

            print(f"   Model: {agg_model}")
            print(f"   é¢„è®¡è€—æ—¶: {agg_config.get('estimated_time', 'æœªçŸ¥')}")

            # æ¨¡æ‹Ÿaggregationæ‰§è¡Œ
            print(f"   â³ æ¨¡æ‹Ÿèšåˆæ‰§è¡Œ...")
            time.sleep(1)  # æ¨¡æ‹Ÿ

            agg_duration = time.time() - agg_start
            print(f"   âœ… èšåˆå®Œæˆï¼Œè€—æ—¶: {agg_duration:.1f}ç§’")

        total_duration = time.time() - task_start

        # è®°å½•æ‰§è¡Œæ—¥å¿—
        log_entry = {
            'task_id': task_id,
            'description': task_desc,
            'subtasks_count': len(subtasks),
            'subtask_duration': subtask_duration,
            'aggregation_duration': agg_duration if agg_config else 0,
            'total_duration': total_duration,
            'estimated_time': task.get('total_estimated_time', 'æœªçŸ¥')
        }
        self.execution_log.append(log_entry)

        print(f"\nâœ… Task {task_id} å®Œæˆ:")
        print(f"   å­ä»»åŠ¡å¹¶è¡Œæ‰§è¡Œ: {subtask_duration:.1f}ç§’")
        if agg_config:
            print(f"   èšåˆ: {agg_duration:.1f}ç§’")
        print(f"   æ€»è®¡: {total_duration:.1f}ç§’")
        print(f"   é¢„è®¡: {task.get('total_estimated_time', 'æœªçŸ¥')}")

        return f"Task {task_id} è¾“å‡ºï¼ˆæ¨¡æ‹Ÿï¼‰", total_duration

    def execute(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„ç ”ç©¶è®¡åˆ’"""
        print(f"\n{'='*70}")
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œå¹¶è¡ŒSubagentä¼˜åŒ–è®¡åˆ’")
        print(f"{'='*70}")
        print(f"è®¡åˆ’: {self.plan_path.name}")
        print(f"ä¸»é¢˜: {self.plan['topic']}")
        print(f"ç‰ˆæœ¬: {self.plan.get('version', 'unknown')}")
        print(f"ä¼˜åŒ–ç­–ç•¥: {self.plan.get('optimization', {}).get('strategy', 'unknown')}")
        print(f"é¢„æœŸæé€Ÿ: {self.plan.get('optimization', {}).get('expected_speedup', 'unknown')}")

        self.start_time = time.time()

        # æ„å»ºæ³¢æ¬¡ç»“æ„
        waves = self._build_wave_structure()
        print(f"\nğŸ“Š æ‰§è¡Œè®¡åˆ’: {len(waves)}ä¸ªæ³¢æ¬¡")

        wave_results = []

        for wave_idx, task_ids in enumerate(waves, 1):
            print(f"\n{'='*70}")
            print(f"Wave {wave_idx}: å¹¶è¡Œæ‰§è¡Œ {len(task_ids)} ä¸ªä»»åŠ¡")
            print(f"{'='*70}")

            wave_start = time.time()
            tasks = [t for t in self.plan['tasks'] if t['id'] in task_ids]

            # åœ¨å®é™…ç¯å¢ƒä¸­ï¼Œè¿™é‡Œåº”è¯¥å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            # å¯¹äºtask-levelå¹¶è¡Œï¼Œä»ç„¶ä½¿ç”¨åŸæœ‰çš„Task tool
            # å¯¹äºsubtask-levelå¹¶è¡Œï¼Œä½¿ç”¨ä¸Šé¢çš„parallel_subagentsæ¨¡å¼

            wave_task_results = []
            for task in tasks:
                result, duration = self.execute_task_with_parallel_subagents(task)
                wave_task_results.append({
                    'task_id': task['id'],
                    'result': result,
                    'duration': duration
                })

            wave_duration = time.time() - wave_start
            wave_results.append({
                'wave': wave_idx,
                'tasks': task_ids,
                'duration': wave_duration
            })

            print(f"\nâœ… Wave {wave_idx} å®Œæˆï¼Œè€—æ—¶: {wave_duration:.1f}ç§’")

        total_duration = time.time() - self.start_time

        # ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š
        report = self._generate_report(wave_results, total_duration)

        return report

    def _generate_report(self, wave_results: List[Dict], total_duration: float) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š"""
        print(f"\n{'='*70}")
        print(f"ğŸ“Š æ‰§è¡ŒæŠ¥å‘Š")
        print(f"{'='*70}")

        baseline_time = 28.3 * 60  # 28.3åˆ†é’Ÿè½¬ç§’
        predicted_time = float(self.plan.get('optimization', {}).get('expected_time', '10åˆ†é’Ÿ').split('åˆ†')[0]) * 60

        print(f"\nâ±ï¸  æ—¶é—´ç»Ÿè®¡:")
        print(f"   å®é™…æ‰§è¡Œæ—¶é—´: {total_duration:.1f}ç§’ ({total_duration/60:.1f}åˆ†é’Ÿ)")
        print(f"   åŸºçº¿æ—¶é—´: {baseline_time:.1f}ç§’ (28.3åˆ†é’Ÿ)")
        print(f"   é¢„æµ‹æ—¶é—´: {predicted_time:.1f}ç§’ ({predicted_time/60:.1f}åˆ†é’Ÿ)")

        if baseline_time > 0:
            speedup = ((baseline_time - total_duration) / baseline_time) * 100
            print(f"   æé€Ÿ: {speedup:.1f}%")

        print(f"\nğŸ“‹ æ³¢æ¬¡è¯¦æƒ…:")
        for wave_result in wave_results:
            print(f"   Wave {wave_result['wave']}: {wave_result['duration']:.1f}ç§’ (Tasks: {wave_result['tasks']})")

        print(f"\nğŸ“‹ ä»»åŠ¡è¯¦æƒ…:")
        for log in self.execution_log:
            print(f"   Task {log['task_id']}: {log['total_duration']:.1f}ç§’")
            print(f"      - å­ä»»åŠ¡: {log['subtasks_count']}ä¸ª, {log['subtask_duration']:.1f}ç§’")
            if log['aggregation_duration'] > 0:
                print(f"      - èšåˆ: {log['aggregation_duration']:.1f}ç§’")
            print(f"      - é¢„è®¡: {log['estimated_time']}")

        report = {
            'plan_file': str(self.plan_path),
            'plan_version': self.plan.get('version'),
            'execution_time': {
                'total_seconds': total_duration,
                'total_minutes': total_duration / 60,
                'baseline_seconds': baseline_time,
                'predicted_seconds': predicted_time,
                'speedup_percent': ((baseline_time - total_duration) / baseline_time) * 100 if baseline_time > 0 else 0
            },
            'waves': wave_results,
            'tasks': self.execution_log,
            'timestamp': datetime.now().isoformat()
        }

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.plan_path.parent / f"execution_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

        return report


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python parallel_executor.py <plan.json>")
        sys.exit(1)

    plan_path = sys.argv[1]

    if not Path(plan_path).exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {plan_path}")
        sys.exit(1)

    executor = ParallelExecutor(plan_path)
    report = executor.execute()

    print(f"\n{'='*70}")
    print(f"âœ… æ‰§è¡Œå®Œæˆ")
    print(f"{'='*70}")


if __name__ == '__main__':
    main()
